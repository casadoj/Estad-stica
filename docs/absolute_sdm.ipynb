{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        def absolute_sdm(obs_c, mod_c ,sce_c, *args, **kwargs):\n",
    "            \"\"\"\n",
    "            apply absolute scaled distribution mapping to all scenario cubes\n",
    "            assuming a normal distributed parameter\n",
    "\n",
    "            Args:\n",
    "\n",
    "            * obs_cube (:class:`iris.cube.Cube`):\n",
    "                the observational data\n",
    "\n",
    "            * mod_cube (:class:`iris.cube.Cube`):\n",
    "                the model data at the reference period\n",
    "\n",
    "            * sce_cubes (:class:`iris.cube.CubeList`):\n",
    "                the scenario data that shall be corrected\n",
    "\n",
    "            Kwargs:\n",
    "\n",
    "            * cdf_threshold (float):\n",
    "                limit of the cdf-values (default: .99999)\n",
    "            \"\"\"\n",
    "            \n",
    "            from scipy.stats import norm\n",
    "            from scipy.signal import detrend\n",
    "            \n",
    "            # extract keywords\n",
    "            cdf_threshold = kwargs.get('cdf_threshold', .99999)\n",
    "            \n",
    "            # STEP 1\n",
    "            # original series their length\n",
    "            data = {'obs': obs_c.copy(),\n",
    "                    'mod': mod_c.copy(),\n",
    "                    'sce': sce_c.copy()}\n",
    "            # length of the series\n",
    "            lens = {key: len(data[key]) for key in data}\n",
    "            # mean of the series\n",
    "            means = {key: data[key].mean() for key in data}\n",
    "            # detrend the data\n",
    "            detrended = key: detrend(data[key]) for key in data}\n",
    "\n",
    "            # STEP 2\n",
    "            # fit normal distribution\n",
    "            pars = {key: norm.fit(detrended[key], floc=0) for key in detrended}\n",
    "            # corresponding cdf values\n",
    "            cdf = {}\n",
    "            for key in detrended:\n",
    "                cdf_aux = norm.cdf(np.sort(detrended[key]), *pars[key])\n",
    "                cdf[key] = np.maximum(np.minimum(cdf_aux, cdf_threshold), 1 - cdf_threshold)\n",
    "                del cdf_aux\n",
    "            \n",
    "            # STEP 3\n",
    "            # scaling factor between the historic and future model\n",
    "            SFa = (norm.ppf(cdf['sce'], *pars['sce']) - norm.ppf(cdf['sce'], *pars['mod']) * \\\n",
    "                   pars['obs'][-1] / pars['mod'][-1]\n",
    "            \n",
    "            # STEP 4\n",
    "            # linearly interpolate cdf-values for 'obs' and 'mod' to the length of the scenario\n",
    "            for key in ['obs', 'mod']:\n",
    "                cdf[key + '_int'] = np.interp(np.linspace(1, lens[key], lens['sce']),\n",
    "                                              np.linspace(1, lens[key], lens[key]),\n",
    "                                              cdf[key])\n",
    "            # split the tails of the cdfs around the center\n",
    "            cdf_shift = {key: cdf[key] - .5 for key in ['obs_int', 'mod_int', 'sce']}\n",
    "            # recurrence intervals\n",
    "            RI = {key: 1. / (.5 - np.abs(cdf_shift[key])) for key in cdf_shift}\n",
    "            \n",
    "            # STEP 5\n",
    "            # find RIscaled for the raw future model\n",
    "            RIscaled = np.maximum(1., RI['obs_int'] * RI['sce'] / RI['mod_int'])\n",
    "            # adapt the observation cdfs\n",
    "#            adapted_cdf = .5 + np.sign(cdf_shift['obs_int']) * np.abs(.5 - 1 / RIscaled)\n",
    "            adapted_cdf = np.sign(cdf_shift['obs_int']) * (1. - 1. / (RI['obs_int'] * RI['sce'] / RI['mod_int']))\n",
    "            adapted_cdf[adapted_cdf < 0] += 1.\n",
    "            adapted_cdf = np.maximum(np.minimum(adapted_cdf, cdf_threshold), 1 - cdf_threshold)\n",
    "            \n",
    "            # STEP 6\n",
    "            # initial array of bias corrected values\n",
    "            xvals = norm.ppf(np.sort(adapted_cdf), *pars['obs']) + SFa\n",
    "            xvals -= xvals.mean()\n",
    "            xvals += means['obs'] + means['sce'] - means['mod']\n",
    "            \n",
    "            # STEP 7\n",
    "            # reinsert the bias corrected values\n",
    "            correction = np.zeros(lens['sce'])\n",
    "            sce_argsort = np.argsort(detrended['sce'])\n",
    "            correction[sce_argsort] = xvals\n",
    "            # add back the trend of the future model\n",
    "            sce_diff = data['sce'] - detrended['sce']\n",
    "            correction += sce_diff - means['sce']\n",
    "            \n",
    "            return correction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
